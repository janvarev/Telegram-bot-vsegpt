import logging
import asyncio
import time
from typing import Dict, List

import openai
from aiogram import Bot, Dispatcher, types, F, BaseMiddleware
from aiogram.filters import Command
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.utils.text_decorations import html_decoration
# from aiogram.utils.markdown import code

from models import LLM_MODELS, SYSTEM_PROMPT
# –í–∫–ª—é—á–∏—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    datefmt='%m-%d %H:%M:%S'
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
from config import (
    API_TELEGRAM_TOKEN,
    API_VSEGPT_TOKEN,
    ALLOWED_USERS,
    VSEGPT_API_BASE
)

bot = Bot(
    token=API_TELEGRAM_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML
                                 )
)
dp = Dispatcher()

openai.api_base = VSEGPT_API_BASE
openai.api_key = API_VSEGPT_TOKEN
bot_users = [int(id_str) for id_str in ALLOWED_USERS.split(':')]
llm_model = LLM_MODELS[0]

class CommonMiddleware(BaseMiddleware):
    async def __call__(self, handler, event: types.Update, data: dict):
        message = event.message
        if message:
            await bot.send_chat_action(chat_id=message.from_user.id, action='typing')

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —á–∞—Ç–∞
            if message.chat.id not in bot_users:
                await message.reply(f"–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –≤–∞—Å –Ω–µ –∑–Ω–∞—é. –ù–µ –ø–∏—à–∏—Ç–µ –º–Ω–µ –±–æ–ª—å—à–µ.\n–ï—Å–ª–∏ —è –¥–æ–ª–∂–µ–Ω –≤–∞—Å –∑–Ω–∞—Ç—å, –ø–µ—Ä–µ–¥–∞–π—Ç–µ –º–æ–µ–º—É –≤–ª–∞–¥–µ–ª—å—Ü—É –≤–∞—à Telegram ID <code>{message.chat.id}</code>")
                return
        
        try:
            result = await handler(event, data)
            await bot.set_message_reaction(chat_id=message.from_user.id, message_id=message.message_id, reaction=[{'type':'emoji', 'emoji':'üëå'}])
            return result
        except Exception as e:
            logging.error(f'Exception: {e}')
            await bot.set_message_reaction(chat_id=message.from_user.id, message_id=message.message_id, reaction=[{'type':'emoji', 'emoji':'ü§∑‚Äç‚ôÇ'}])
            await answer_message(message, f'ü§∑‚Äç‚ôÇÔ∏è –û—à–∏–±–∫–∞: {e}')
            return

dp.update.middleware(CommonMiddleware())  # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è middleware

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤
conversation_history = {}
# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_models = {}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
def trim_history(history: list, max_length=4096):
    current_length = sum(len(message["content"]) for message in history)
    while history and current_length > max_length:
        removed_message = history.pop(0)
        current_length -= len(removed_message["content"])
    return history

async def change_model(message: types.Message, model = None) -> None:
    user_id = message.from_user.id
    current_model = user_models.get(user_id, LLM_MODELS[0])
    
    if not model:
        # –ï—Å–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        models_list = "\n".join([f"<code>/model {model}</code>" for model in LLM_MODELS])
        await answer_message(message, 
            f"–°–µ–π—á–∞—Å –≤—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å {current_model}" + 
            "\n\n–ù–∞–∂–º–∏ –Ω–∞ –∫–æ–º–∞–Ω–¥—É –≤—ã–±–æ—Ä–∞ –æ–¥–Ω–æ–π –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, —á—Ç–æ–±—ã —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –µ—ë, –∞ –∑–∞—Ç–µ–º –æ—Ç–ø—Ä–∞–≤—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –º–Ω–µ:\n\n" + models_list +
            "\n\n–ú–æ–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –≤ –∫–æ–º–∞–Ω–¥–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤—Ä—É—á–Ω—É—é, –Ω–æ –µ—Å–ª–∏ —Ç–∞–∫–æ–π –º–æ–¥–µ–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ç–æ –≤–º–µ—Å—Ç–æ –æ—Ç–≤–µ—Ç–∞ —è –≤–µ—Ä–Ω—É –æ—à–∏–±–∫—É. –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –≤—ã–±–µ—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å."
        )
        return
    
    user_models[user_id] = model
    await answer_message(message, f"–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ <b>{model}</b>.")

@dp.message(Command('start'))
async def process_start_command(message: types.Message):
    commands_info = """
–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –ò–ò-–±–æ—Ç!

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/start - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
/model - –ø—Ä–æ—Å–º–æ—Ç—Ä –∏ –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ò–ò
... –±–æ–ª—å—à–µ –∫–æ–º–∞–Ω–¥ –≤ –º–µ–Ω—é

–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Å–≤–æ–∏ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –º—ã—Å–ª–∏, –∏ —è –±—É–¥—É –Ω–∞ –Ω–∏—Ö –æ—Ç–≤–µ—á–∞—Ç—å!
"""
    await answer_message(message, commands_info)


@dp.message(Command('clear'))
async def process_clear_command(message: types.Message):
    user_id = message.from_user.id
    conversation_history[user_id] = []
    await answer_message(message, "–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")


@dp.message(Command('model'))
async def process_model_command(message: types.Message):
    """Handle model selection command"""
    
    # –ü–æ–ª—É—á–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç –∫–æ–º–∞–Ω–¥—ã
    args = message.text.split()[1:]
    model = args[0] if len(args) > 0 else None
    await change_model(message, model)    

@dp.message(Command('sonnet'))
async def process_model_sonnet_command(message: types.Message):
    await change_model(message, "anthropic/claude-3.5-sonnet")

@dp.message(Command('haiku'))
async def process_model_haiku_command(message: types.Message):
    await change_model(message, "anthropic/claude-3-5-haiku")

@dp.message(Command('gpt'))
async def process_model_haiku_command(message: types.Message):
    await change_model(message, "openai/gpt-4o-latest")

@dp.message(Command('gemini'))
async def process_model_gemini_command(message: types.Message):
    await change_model(message, "google/gemini-pro-1.5")

@dp.message(F.text)
async def process_message(message: types.Message):
    user_id = message.from_user.id
    if user_id not in bot_users:
        await answer_message(message, "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –≤–∞—Å –Ω–µ –∑–Ω–∞—é. –ù–µ –ø–∏—à–∏—Ç–µ –º–Ω–µ –±–æ–ª—å—à–µ")
        return
    
    user_input = message.text
    if message.from_user.username:
        username = "@" + message.from_user.username
    else:
        username = "user"
    logging.info(f"Got text from {username} ({user_id}), len: {len(user_input)}")

    if user_id not in conversation_history:
        conversation_history[user_id] = []

    conversation_history[user_id].append({"role": "user", "content": user_input})
    conversation_history[user_id] = trim_history(conversation_history[user_id])

    chat_history = conversation_history[user_id]

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        current_model = user_models.get(user_id, LLM_MODELS[0])
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∫ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
        full_messages = [SYSTEM_PROMPT] + chat_history
        response = await openai.ChatCompletion.acreate(
            model=current_model,
            messages=full_messages
        )
        if isinstance(response, dict):
            chat_gpt_response = response["choices"][0]["message"]["content"]
        else:
            chat_gpt_response = str(response)
          
        logging.info(f"Got AI answer, len: {len(chat_gpt_response)}")

        # print(f"{chat_gpt_response=}")

        chat_gpt_response = html_decoration.quote(chat_gpt_response)
    except Exception as e:
        logging.error(e)
        chat_gpt_response = f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"

    conversation_history[user_id].append({"role": "assistant", "content": chat_gpt_response})
    # print(conversation_history)
    length = sum(len(message["content"]) for message in conversation_history[user_id])
    # print(length)
    await answer_message(message, chat_gpt_response)

async def answer_message(message: types.Message, answer_text: str):
    # Telegram limit is 4096 characters in a message
    msg_len_limit = 4000
    if len(answer_text) <= msg_len_limit:
        await message.answer(answer_text)
    else:
        chunks = text_to_chunks(answer_text, msg_len_limit)
        for chunk in chunks:
            try:
                await message.answer(chunk)
            except Exception as e:
                await message.answer(f'ü§∑‚Äç‚ôÇÔ∏è {e}')
            time.sleep(0.03)


def text_to_chunks(text, max_len):
    """ Accepts a string text and splits it into parts of up to max_len characters. Returns a list of parts"""
    sentences = [piece.strip() + '.' for piece in text.split('.')]
    texts = []
    chunk = ''

    for sentence in sentences:
        if len(sentence) > max_len or len(chunk + ' ' + sentence) > max_len:
            # This sentence does not fit into the current chunk
            if len(chunk) > 0:
                # If there is something in the chunk, save it
                texts.append(chunk.strip(' '))
                chunk = ''
            # Chunk is empty, start filling it
            if len(sentence) > max_len:
                # If the current sentence is too long, put only as much as fits into the chunk
                words = sentence.split(' ')
                for word in words:
                    if len(chunk + ' ' + word) < max_len:
                        # This word fits into the current chunk, add it
                        chunk += ' ' + word
                    else:
                        # This word does not fit into the current chunk
                        texts.append(chunk.strip(' '))
                        chunk = word
            else:
                # Chunk was empty, so just add the sentence to it
                chunk = sentence

        else:
            # This sentence fits into the current chunk, add it
            chunk += ' ' + sentence
    # Save the last chunk, if it is not empty
    if len(chunk) > 0: texts.append(chunk.strip(' '))
    return texts

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–º–∞–Ω–¥ –±–æ—Ç–∞
async def set_commands():
    commands = [
        types.BotCommand(command="clear", description="–°–º–µ–Ω–∏—Ç—å —Ç–µ–º—É –∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥"),
        types.BotCommand(command="sonnet", description="–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å anthropic/claude-3.5-sonnet"),
        types.BotCommand(command="haiku", description="–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å anthropic/claude-3-5-haiku"),
        types.BotCommand(command="gpt", description="–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å openai/gpt-4o-latest"),
        types.BotCommand(command="gemini", description="–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å google/gemini-pro-1.5"),
        types.BotCommand(command="model", description="–í—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –ò–ò"),
    ]
    await bot.set_my_commands(commands)

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await set_commands()  # –î–æ–±–∞–≤–ª—è–µ–º —ç—Ç—É —Å—Ç—Ä–æ–∫—É
    await dp.start_polling(bot)

if __name__ == '__main__':
    asyncio.run(main())
